# ========================================
# API Keys
# ========================================
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...

# Database Configuration
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/guidance_agent

# ========================================
# LLM Model Configuration
# ========================================
# The system supports multiple LLM providers via LiteLLM.
# Uncomment the provider configuration you want to use.

# ----------------------------------------
# OPTION 1: OpenAI (Default)
# ----------------------------------------
LITELLM_MODEL_ADVISOR=gpt-4-turbo-preview
LITELLM_MODEL_CUSTOMER=gpt-3.5-turbo
LITELLM_MODEL_EMBEDDINGS=text-embedding-3-small
EMBEDDING_DIMENSION=1536

# Supported OpenAI models:
# - gpt-4o (latest, supports caching)
# - gpt-4-turbo-preview (supports caching)
# - gpt-4
# - gpt-3.5-turbo
# - text-embedding-3-small (1536 dim)
# - text-embedding-3-large (3072 dim)

# ----------------------------------------
# OPTION 2: Anthropic Claude
# ----------------------------------------
#LITELLM_MODEL_ADVISOR=claude-sonnet-4.5
#LITELLM_MODEL_CUSTOMER=claude-haiku-4.5
#LITELLM_MODEL_EMBEDDINGS=voyage-large-2
#ANTHROPIC_API_KEY=sk-ant-...
#VOYAGE_API_KEY=...  # For Voyage embeddings

# Supported Anthropic models:
# - claude-sonnet-4.5 (latest, supports caching)
# - claude-opus-4 (highest quality)
# - claude-haiku-4.5 (fastest, cheapest)

# ----------------------------------------
# OPTION 3: AWS Bedrock
# ----------------------------------------
#LITELLM_MODEL_ADVISOR=bedrock/anthropic.claude-3-5-sonnet-20240229-v1:0
#LITELLM_MODEL_CUSTOMER=bedrock/anthropic.claude-3-haiku-20240307-v1:0
#LITELLM_MODEL_EMBEDDINGS=bedrock/amazon.titan-embed-text-v1
#AWS_ACCESS_KEY_ID=your-access-key
#AWS_SECRET_ACCESS_KEY=your-secret-key
#AWS_REGION_NAME=us-east-1

# Supported Bedrock models:
# - bedrock/anthropic.claude-3-5-sonnet-20240229-v1:0
# - bedrock/anthropic.claude-3-haiku-20240307-v1:0
# - bedrock/anthropic.claude-3-opus-20240229-v1:0
# - bedrock/amazon.titan-embed-text-v1 (1536 dim)
# - bedrock/cohere.embed-english-v3 (1024 dim)

# ----------------------------------------
# OPTION 4: LM Studio (Local)
# ----------------------------------------
#LITELLM_MODEL_ADVISOR=lmstudio/llama-3.1-70b-instruct
#LITELLM_MODEL_CUSTOMER=lmstudio/llama-3.1-8b-instruct
#LITELLM_MODEL_EMBEDDINGS=lmstudio/nomic-embed-text
#OPENAI_API_BASE=http://localhost:1234/v1
#EMBEDDING_DIMENSION=768  # Required for local embeddings

# Prerequisites:
# 1. Install LM Studio: https://lmstudio.ai
# 2. Download models in LM Studio
# 3. Start local server in LM Studio (default port: 1234)

# Supported LM Studio models:
# - lmstudio/llama-3.1-70b-instruct (best quality)
# - lmstudio/llama-3.1-8b-instruct (faster)
# - lmstudio/mistral-7b-instruct
# - lmstudio/nomic-embed-text (768 dim)

# ----------------------------------------
# OPTION 5: Ollama (Local)
# ----------------------------------------
#LITELLM_MODEL_ADVISOR=ollama/llama3.1:70b
#LITELLM_MODEL_CUSTOMER=ollama/llama3.1:8b
#LITELLM_MODEL_EMBEDDINGS=ollama/nomic-embed-text
#EMBEDDING_DIMENSION=768  # Required for local embeddings

# Prerequisites:
# 1. Install Ollama: https://ollama.ai
# 2. Pull models: ollama pull llama3.1:70b
# 3. Pull embeddings: ollama pull nomic-embed-text

# Supported Ollama models:
# - ollama/llama3.1:70b (best quality)
# - ollama/llama3.1:8b (faster)
# - ollama/mistral (good alternative)
# - ollama/nomic-embed-text (768 dim)
# - ollama/bge-large (1024 dim)

# ----------------------------------------
# OPTION 6: Azure OpenAI
# ----------------------------------------
#LITELLM_MODEL_ADVISOR=azure/your-gpt4-deployment
#LITELLM_MODEL_CUSTOMER=azure/your-gpt35-deployment
#LITELLM_MODEL_EMBEDDINGS=azure/your-embedding-deployment
#AZURE_API_KEY=...
#AZURE_API_BASE=https://your-resource.openai.azure.com
#AZURE_API_VERSION=2024-02-15-preview

# Note: Deployment names are specific to your Azure setup

# ========================================
# Phoenix Configuration
# ========================================
PHOENIX_COLLECTOR_ENDPOINT=http://localhost:4317
PHOENIX_PROJECT_NAME=guidance-agent

# ========================================
# Application Settings
# ========================================
ENVIRONMENT=development
LOG_LEVEL=INFO
